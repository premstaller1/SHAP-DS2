{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\osi0pr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\osi0pr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\osi0pr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\osi0pr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk \n",
    "import string\n",
    "import re\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data to prepare for sentiment analysis\n",
    "data = pd.read_excel('data/stockwits/stockwits_crypto.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: (600000, 2)\n",
      "Dataset columns: Index(['text', 'label'], dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 599975 entries, 0 to 599999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    599975 non-null  object\n",
      " 1   label   599975 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 13.7+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>if you were curious, price chose the lowest ch...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>true, not even 10k followers here yet.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dogecoin co-founder billy markus hits back at ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i’m curious, do any bulls have a price where ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>friday everybody buy 10 more on friday</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  if you were curious, price chose the lowest ch...      1\n",
       "1             true, not even 10k followers here yet.      1\n",
       "2  dogecoin co-founder billy markus hits back at ...      1\n",
       "3   i’m curious, do any bulls have a price where ...      1\n",
       "4             friday everybody buy 10 more on friday      2"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#inspect the relevant data column and look for issues\n",
    "print('Dataset size:',data.shape)\n",
    "print('Dataset columns:',data.columns)\n",
    "#remove any rows with missing data\n",
    "data = data.dropna()\n",
    "data.info()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweets_column(df, column_name, cleaned_column):\n",
    "    def clean_tweet(tweet):\n",
    "        # Convert to string if it's not already\n",
    "        tweet = str(tweet)\n",
    "        # Remove hyperlinks\n",
    "        tweet = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', tweet, flags=re.MULTILINE)\n",
    "        # Remove user @ references and '#' from hashtags\n",
    "        tweet = re.sub(r'\\@\\w+|\\#','', tweet)\n",
    "        # Remove emojis\n",
    "        tweet = re.sub(r'[^\\x00-\\x7F]+', '', tweet)\n",
    "        # Remove new lines\n",
    "        tweet = tweet.replace('\\n', ' ')\n",
    "        # Remove extra spaces\n",
    "        tweet = re.sub(r'\\s+', ' ', tweet).strip()\n",
    "        # Convert to lowercase\n",
    "        tweet = tweet.lower()\n",
    "        # Remove special characters, numbers, and punctuations\n",
    "        tweet = \"\".join([char for char in tweet if char not in string.punctuation])\n",
    "        tweet = re.sub('[0-9]+', '', tweet)\n",
    "        return tweet\n",
    "\n",
    "    def remove_stopwords(tweet):\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        tweet_tokens = tweet.split()\n",
    "        filtered_tweet = [word for word in tweet_tokens if word not in stop_words]\n",
    "        return ' '.join(filtered_tweet)\n",
    "\n",
    "    # Apply the clean_tweet function to the specified column\n",
    "    df[cleaned_column] = df[column_name].astype(str).apply(clean_tweet)\n",
    "    # Remove stop words\n",
    "    df[cleaned_column] = df[cleaned_column].apply(remove_stopwords)\n",
    "\n",
    "# Example usage\n",
    "clean_tweets_column(data, 'tweet_text', 'clean_tweet_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text:\n",
      " 0        golds massive range past year weve swept lows ...\n",
      "1        rt spx daily chart target bull move mentioned ...\n",
      "2        rt ndx daily chart target bull move mentioned ...\n",
      "3        rt iwm daily chart target bull move mentioned ...\n",
      "4        rt everyone concerned concentration stockmarke...\n",
      "                               ...                        \n",
      "22378                                  trade dxy trade dxy\n",
      "22379    get apology im glad agree dxy looking bad bear...\n",
      "22380    ecb hawkish fed coming end hiking cycle bearis...\n",
      "22381                         dxy monster intraday reclaim\n",
      "22382                                dxy starting daily eq\n",
      "Name: clean_tweet_text, Length: 22383, dtype: object\n",
      "\n",
      "Stemmed Text:\n",
      " 0        gold massiv rang past year weve swept low high...\n",
      "1        rt spx daili chart target bull move mention be...\n",
      "2        rt ndx daili chart target bull move mention be...\n",
      "3        rt iwm daili chart target bull move mention la...\n",
      "4        rt everyon concern concentr stockmarket well n...\n",
      "                               ...                        \n",
      "22378                                  trade dxi trade dxi\n",
      "22379    get apolog im glad agre dxi look bad bearish r...\n",
      "22380    ecb hawkish fed come end hike cycl bearish dxi...\n",
      "22381                         dxi monster intraday reclaim\n",
      "22382                                   dxi start daili eq\n",
      "Name: stemmed_text, Length: 22383, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Initialize Porter Stemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Function to apply stemming to a text\n",
    "def stem_text(text):\n",
    "    tokens = word_tokenize(text)  # Tokenize the text\n",
    "    stemmed_words = [stemmer.stem(word) for word in tokens]  # Stem each token\n",
    "    return \" \".join(stemmed_words)  # Join stemmed tokens back into a single string\n",
    "\n",
    "# Apply stemming to the 'tweet_text_cleaned' column\n",
    "data['stemmed_text'] = data['clean_tweet_text'].apply(stem_text)\n",
    "\n",
    "# Display the original and stemmed text\n",
    "print(\"Original Text:\\n\", data['clean_tweet_text'])\n",
    "print(\"\\nStemmed Text:\\n\", data['stemmed_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new csv file with cleaned data\n",
    "data.to_csv('data/finance_stocks/finance_stocks-train-cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
