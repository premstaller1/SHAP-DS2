{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\osi0pr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\osi0pr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\osi0pr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\osi0pr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk \n",
    "import string\n",
    "import re\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data to prepare for sentiment analysis\n",
    "data = pd.read_csv('data/finance_stocks/finance_stocks-train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: (14363, 8)\n",
      "Dataset columns: Index(['timestamp', 'tweet_text', 'tweet_url', 'tweet_type', 'price_of_ticker',\n",
      "       'change_of_ticker', 'tickers_mentioned', 'category'],\n",
      "      dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 14363 entries, 0 to 22382\n",
      "Data columns (total 8 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   timestamp          14363 non-null  object\n",
      " 1   tweet_text         14363 non-null  object\n",
      " 2   tweet_url          14363 non-null  object\n",
      " 3   tweet_type         14363 non-null  object\n",
      " 4   price_of_ticker    14363 non-null  object\n",
      " 5   change_of_ticker   14363 non-null  object\n",
      " 6   tickers_mentioned  14363 non-null  object\n",
      " 7   category           14363 non-null  object\n",
      "dtypes: object(8)\n",
      "memory usage: 1009.9+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>tweet_url</th>\n",
       "      <th>tweet_type</th>\n",
       "      <th>price_of_ticker</th>\n",
       "      <th>change_of_ticker</th>\n",
       "      <th>tickers_mentioned</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-11-15T09:36:42.028000+00:00</td>\n",
       "      <td>$GOLD's Massive Range.\\n\\nIn the past ~year we...</td>\n",
       "      <td>https://twitter.com/user/status/17247221551437...</td>\n",
       "      <td>tweet</td>\n",
       "      <td>['15.71']</td>\n",
       "      <td>['+3.69%']</td>\n",
       "      <td>['$GOLD']</td>\n",
       "      <td>stock_images</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-11-15T06:01:59.788000+00:00</td>\n",
       "      <td>RT @SmartReversals: $SPX - Daily Chart:\\n\\n✅Ta...</td>\n",
       "      <td>https://twitter.com/user/status/17246687922221...</td>\n",
       "      <td>retweet</td>\n",
       "      <td>['4495.71']</td>\n",
       "      <td>['+1.87%']</td>\n",
       "      <td>['$SPX']</td>\n",
       "      <td>stock_images</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-11-15T06:01:55.590000+00:00</td>\n",
       "      <td>RT @SmartReversals: $NDX - Daily Chart:\\n\\n✅Ta...</td>\n",
       "      <td>https://twitter.com/user/status/17246687824535...</td>\n",
       "      <td>retweet</td>\n",
       "      <td>['15812.473']</td>\n",
       "      <td>['+2.08%']</td>\n",
       "      <td>['$NDX']</td>\n",
       "      <td>stock_images</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-11-15T06:01:51.329000+00:00</td>\n",
       "      <td>RT @SmartReversals: $IWM - Daily Chart:\\n\\n✅Ta...</td>\n",
       "      <td>https://twitter.com/user/status/17246687591081...</td>\n",
       "      <td>retweet</td>\n",
       "      <td>['178.46']</td>\n",
       "      <td>['+5.21%']</td>\n",
       "      <td>['$IWM']</td>\n",
       "      <td>stock_images</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-11-15T04:01:49.009000+00:00</td>\n",
       "      <td>RT @coiledspringcap: Everyone has been concern...</td>\n",
       "      <td>https://twitter.com/user/status/17246376898767...</td>\n",
       "      <td>retweet</td>\n",
       "      <td>['4495.71']</td>\n",
       "      <td>['+1.87%']</td>\n",
       "      <td>['$SPX']</td>\n",
       "      <td>stock_images</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          timestamp  \\\n",
       "0  2023-11-15T09:36:42.028000+00:00   \n",
       "1  2023-11-15T06:01:59.788000+00:00   \n",
       "2  2023-11-15T06:01:55.590000+00:00   \n",
       "3  2023-11-15T06:01:51.329000+00:00   \n",
       "4  2023-11-15T04:01:49.009000+00:00   \n",
       "\n",
       "                                          tweet_text  \\\n",
       "0  $GOLD's Massive Range.\\n\\nIn the past ~year we...   \n",
       "1  RT @SmartReversals: $SPX - Daily Chart:\\n\\n✅Ta...   \n",
       "2  RT @SmartReversals: $NDX - Daily Chart:\\n\\n✅Ta...   \n",
       "3  RT @SmartReversals: $IWM - Daily Chart:\\n\\n✅Ta...   \n",
       "4  RT @coiledspringcap: Everyone has been concern...   \n",
       "\n",
       "                                           tweet_url tweet_type  \\\n",
       "0  https://twitter.com/user/status/17247221551437...      tweet   \n",
       "1  https://twitter.com/user/status/17246687922221...    retweet   \n",
       "2  https://twitter.com/user/status/17246687824535...    retweet   \n",
       "3  https://twitter.com/user/status/17246687591081...    retweet   \n",
       "4  https://twitter.com/user/status/17246376898767...    retweet   \n",
       "\n",
       "  price_of_ticker change_of_ticker tickers_mentioned      category  \n",
       "0       ['15.71']       ['+3.69%']         ['$GOLD']  stock_images  \n",
       "1     ['4495.71']       ['+1.87%']          ['$SPX']  stock_images  \n",
       "2   ['15812.473']       ['+2.08%']          ['$NDX']  stock_images  \n",
       "3      ['178.46']       ['+5.21%']          ['$IWM']  stock_images  \n",
       "4     ['4495.71']       ['+1.87%']          ['$SPX']  stock_images  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#inspect the relevant data column and look for issues\n",
    "print('Dataset size:',data.shape)\n",
    "print('Dataset columns:',data.columns)\n",
    "#remove any rows with missing data\n",
    "data = data.dropna()\n",
    "data.info()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweets_column(df, column_name, cleaned_column):\n",
    "    def clean_tweet(tweet):\n",
    "        # Convert to string if it's not already\n",
    "        tweet = str(tweet)\n",
    "        # Remove hyperlinks\n",
    "        tweet = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', tweet, flags=re.MULTILINE)\n",
    "        # Remove user @ references and '#' from hashtags\n",
    "        tweet = re.sub(r'\\@\\w+|\\#','', tweet)\n",
    "        # Remove emojis\n",
    "        tweet = re.sub(r'[^\\x00-\\x7F]+', '', tweet)\n",
    "        # Remove new lines\n",
    "        tweet = tweet.replace('\\n', ' ')\n",
    "        # Remove extra spaces\n",
    "        tweet = re.sub(r'\\s+', ' ', tweet).strip()\n",
    "        # Convert to lowercase\n",
    "        tweet = tweet.lower()\n",
    "        # Remove special characters, numbers, and punctuations\n",
    "        tweet = \"\".join([char for char in tweet if char not in string.punctuation])\n",
    "        tweet = re.sub('[0-9]+', '', tweet)\n",
    "        return tweet\n",
    "\n",
    "    def remove_stopwords(tweet):\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        tweet_tokens = tweet.split()\n",
    "        filtered_tweet = [word for word in tweet_tokens if word not in stop_words]\n",
    "        return ' '.join(filtered_tweet)\n",
    "\n",
    "    # Apply the clean_tweet function to the specified column\n",
    "    df[cleaned_column] = df[column_name].astype(str).apply(clean_tweet)\n",
    "    # Remove stop words\n",
    "    df[cleaned_column] = df[cleaned_column].apply(remove_stopwords)\n",
    "\n",
    "# Example usage\n",
    "clean_tweets_column(data, 'tweet_text', 'clean_tweet_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text:\n",
      " 0        golds massive range past year weve swept lows ...\n",
      "1        rt spx daily chart target bull move mentioned ...\n",
      "2        rt ndx daily chart target bull move mentioned ...\n",
      "3        rt iwm daily chart target bull move mentioned ...\n",
      "4        rt everyone concerned concentration stockmarke...\n",
      "                               ...                        \n",
      "22378                                  trade dxy trade dxy\n",
      "22379    get apology im glad agree dxy looking bad bear...\n",
      "22380    ecb hawkish fed coming end hiking cycle bearis...\n",
      "22381                         dxy monster intraday reclaim\n",
      "22382                                dxy starting daily eq\n",
      "Name: clean_tweet_text, Length: 22383, dtype: object\n",
      "\n",
      "Stemmed Text:\n",
      " 0        gold massiv rang past year weve swept low high...\n",
      "1        rt spx daili chart target bull move mention be...\n",
      "2        rt ndx daili chart target bull move mention be...\n",
      "3        rt iwm daili chart target bull move mention la...\n",
      "4        rt everyon concern concentr stockmarket well n...\n",
      "                               ...                        \n",
      "22378                                  trade dxi trade dxi\n",
      "22379    get apolog im glad agre dxi look bad bearish r...\n",
      "22380    ecb hawkish fed come end hike cycl bearish dxi...\n",
      "22381                         dxi monster intraday reclaim\n",
      "22382                                   dxi start daili eq\n",
      "Name: stemmed_text, Length: 22383, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Initialize Porter Stemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Function to apply stemming to a text\n",
    "def stem_text(text):\n",
    "    tokens = word_tokenize(text)  # Tokenize the text\n",
    "    stemmed_words = [stemmer.stem(word) for word in tokens]  # Stem each token\n",
    "    return \" \".join(stemmed_words)  # Join stemmed tokens back into a single string\n",
    "\n",
    "# Apply stemming to the 'tweet_text_cleaned' column\n",
    "data['stemmed_text'] = data['clean_tweet_text'].apply(stem_text)\n",
    "\n",
    "# Display the original and stemmed text\n",
    "print(\"Original Text:\\n\", data['clean_tweet_text'])\n",
    "print(\"\\nStemmed Text:\\n\", data['stemmed_text'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
